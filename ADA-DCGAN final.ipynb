{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YQZ4-Mdwo9TU","outputId":"092e027b-a479-4e38-b39a-3ce751e1c6e4"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:06<00:00, 28.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50] Batch 0/391 Loss_D: 1.3982 Loss_G: 0.5310 D(x): 0.5271 D(G(z)): 0.5101 ADA_p: 0.010\n","Epoch [1/50] Batch 100/391 Loss_D: 2.2769 Loss_G: 0.4956 D(x): 0.2862 D(G(z)): 0.6638 ADA_p: 0.000\n","Epoch [1/50] Batch 200/391 Loss_D: 1.8378 Loss_G: 0.6385 D(x): 0.3405 D(G(z)): 0.5557 ADA_p: 0.000\n","Epoch [1/50] Batch 300/391 Loss_D: 1.7484 Loss_G: 0.6984 D(x): 0.3400 D(G(z)): 0.5158 ADA_p: 0.000\n","Epoch [2/50] Batch 0/391 Loss_D: 1.6096 Loss_G: 0.7032 D(x): 0.4061 D(G(z)): 0.5159 ADA_p: 0.000\n","Epoch [2/50] Batch 100/391 Loss_D: 1.5289 Loss_G: 0.7469 D(x): 0.4104 D(G(z)): 0.4800 ADA_p: 0.000\n","Epoch [2/50] Batch 200/391 Loss_D: 1.5047 Loss_G: 0.7630 D(x): 0.4106 D(G(z)): 0.4720 ADA_p: 0.000\n","Epoch [2/50] Batch 300/391 Loss_D: 1.6013 Loss_G: 0.6935 D(x): 0.4170 D(G(z)): 0.5251 ADA_p: 0.000\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import os\n","\n","# ------------------------------\n","# 1. Hyperparameters and Device\n","# ------------------------------\n","batch_size = 128\n","image_size = 32\n","latent_dim = 100\n","num_epochs = 50\n","lr_G = 0.0002\n","lr_D = 0.00005\n","beta1 = 0.5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","os.makedirs('generated_images', exist_ok=True)\n","os.makedirs('fid_fake_images', exist_ok=True)\n","\n","# ------------------------------\n","# 2. Augmentation (gentle to start)\n","# ------------------------------\n","ada_aug_p = 0.0\n","ada_target = 0.6\n","ada_interval = 4\n","ada_speed = 0.01\n","ada_history = []\n","\n","ada_aug = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","])\n","\n","def ada_augment(x, p):\n","    \"\"\"Augments a batch x with probability p using the augmentation pipeline.\"\"\"\n","    if p == 0:\n","        return x\n","    x_aug = []\n","    for img in x:\n","        if random.random() < p:\n","            img_pil = transforms.ToPILImage()(img.cpu())\n","            img_pil = ada_aug(img_pil)\n","            img = transforms.ToTensor()(img_pil)\n","        x_aug.append(img)\n","    return torch.stack(x_aug).to(x.device)\n","\n","# ------------------------------\n","# 3. DCGAN Architectures\n","# ------------------------------\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),   # [batch, 512, 4, 4]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),          # [batch, 256, 8, 8]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),          # [batch, 128, 16, 16]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),           # [batch, 64, 32, 32]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 3, 3, 1, 1, bias=False),             # [batch, 3, 32, 32]\n","            nn.Tanh()\n","        )\n","    def forward(self, x):\n","        return self.main(x)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(3, 32, 4, 2, 1, bias=False),        # [batch, 32, 16, 16]\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.4),\n","            nn.Conv2d(32, 64, 4, 2, 1, bias=False),       # [batch, 64, 8, 8]\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.4),\n","            nn.Conv2d(64, 128, 4, 2, 1, bias=False),      # [batch, 128, 4, 4]\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 1, 4, 1, 0, bias=False),       # [batch, 1, 1, 1]\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        out = self.main(x)                   # [batch, 1, 1, 1]\n","        return out.view(x.size(0))           # [batch]\n","\n","# ------------------------------\n","# 4. Data\n","# ------------------------------\n","transform_train = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3)\n","])\n","trainset = datasets.CIFAR10(root='./data', download=True, transform=transform_train)\n","dataloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","# ------------------------------\n","# 5. Initialize Models and Optimizers\n","# ------------------------------\n","netG = Generator().to(device)\n","netD = Discriminator().to(device)\n","optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, 0.999))\n","criterion = nn.BCELoss()\n","\n","# ------------------------------\n","# 6. Training Loop with ADA\n","# ------------------------------\n","real_label = 0.9\n","fake_label = 0.0\n","g_losses, d_losses = [], []\n","\n","for epoch in range(num_epochs):\n","    for i, (real_images, _) in enumerate(dataloader):\n","        b_size = real_images.size(0)\n","        ############################\n","        # (1) Update D network\n","        ###########################\n","        netD.zero_grad()\n","        real_images = real_images.to(device)\n","        real_images_aug = ada_augment(real_images, ada_aug_p)\n","        output_real = netD(real_images_aug)\n","        label_real = torch.full_like(output_real, real_label, device=device)\n","        errD_real = criterion(output_real, label_real)\n","        D_x = output_real.mean().item()\n","        errD_real.backward()\n","\n","        noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n","        fake_images = netG(noise)\n","        fake_images_aug = ada_augment(fake_images.detach(), ada_aug_p)\n","        output_fake = netD(fake_images_aug)\n","        label_fake = torch.full_like(output_fake, fake_label, device=device)\n","        errD_fake = criterion(output_fake, label_fake)\n","        D_G_z1 = output_fake.mean().item()\n","        errD_fake.backward()\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network MORE OFTEN\n","        ###########################\n","        for _ in range(2):  # Two G updates for each D\n","            netG.zero_grad()\n","            noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n","            fake_images = netG(noise)\n","            gen_imgs_aug = ada_augment(fake_images, ada_aug_p)\n","            output_gen = netD(gen_imgs_aug)\n","            label_gen = torch.full_like(output_gen, real_label, device=device)\n","            errG = criterion(output_gen, label_gen)\n","            errG.backward()\n","            optimizerG.step()\n","\n","        errD = errD_real + errD_fake\n","        g_losses.append(errG.item())\n","        d_losses.append(errD.item())\n","\n","        if i % ada_interval == 0:\n","            with torch.no_grad():\n","                pred = netD(real_images_aug)\n","                real_acc = ((pred > 0.5).float().mean().item())\n","                ada_history.append(real_acc)\n","            if real_acc > ada_target:\n","                ada_aug_p = min(1.0, ada_aug_p + ada_speed)\n","            else:\n","                ada_aug_p = max(0.0, ada_aug_p - ada_speed)\n","\n","        if i % 100 == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(dataloader)} \"\n","                  f\"Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} \"\n","                  f\"D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} ADA_p: {ada_aug_p:.3f}\")\n","\n","\n","    # Save images per epoch for monitoring\n","    with torch.no_grad():\n","        fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n","        fake = netG(fixed_noise).detach().cpu()\n","        vutils.save_image(fake, f\"generated_images/ada_dcgan_epoch_{epoch:03d}.png\", normalize=True, nrow=8)\n","\n","# Save model weights\n","torch.save(netG.state_dict(), \"ada_dcgan_gen.pth\")\n","torch.save(netD.state_dict(), \"ada_dcgan_disc.pth\")\n","\n","# Plot loss curves\n","plt.figure()\n","plt.plot(g_losses, label='Generator Loss')\n","plt.plot(d_losses, label='Discriminator Loss')\n","plt.legend()\n","plt.title(\"GAN Losses\")\n","plt.show()\n","\n","# --------------- FID EVALUATION ---------------\n","def generate_samples_for_fid(generator, device, latent_dim=100, num_samples=5000, outdir='fid_fake_images'):\n","    os.makedirs(outdir, exist_ok=True)\n","    generator.eval()\n","    idx = 0\n","    with torch.no_grad():\n","        while idx < num_samples:\n","            z = torch.randn(64, latent_dim, 1, 1, device=device)\n","            imgs = generator(z)\n","            imgs = (imgs + 1) / 2  # [-1,1] to [0,1]\n","            for i in range(imgs.size(0)):\n","                vutils.save_image(imgs[i], f\"{outdir}/fake_{idx+i}.png\")\n","            idx += imgs.size(0)\n","    print(f\"{num_samples} FID-ready fake images saved to: {outdir}\")\n","\n","generate_samples_for_fid(netG, device, latent_dim=latent_dim, num_samples=5000, outdir=\"fid_fake_images\")\n","print(\"To compute the FID, run: python -m pytorch_fid fid_fake_images cifar10_test_real\")\n","\n","# --------------- SINGLE GRID FOR VISUALIZATION ---------------\n","with torch.no_grad():\n","    fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n","    fake_images = netG(fixed_noise).detach().cpu()\n","    vutils.save_image(\n","        fake_images,\n","        \"ada_dcgan_sample_grid.png\",\n","        normalize=True,\n","        nrow=8\n","    )\n","print(\"Saved ADA-DCGAN visual sample grid to 'ada_dcgan_sample_grid.png'.\")\n","\n","# --- Show grid inline (if in notebook) ---\n","try:\n","    from PIL import Image\n","    img = Image.open(\"ada_dcgan_sample_grid.png\")\n","    plt.figure(figsize=(7,7))\n","    plt.axis(\"off\")\n","    plt.title(\"ADA-DCGAN Sample Grid\")\n","    plt.imshow(img)\n","    plt.show()\n","except Exception as e:\n","    print(\"Image preview unavailable:\", e)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6456,"status":"ok","timestamp":1764024241547,"user":{"displayName":"Akhila R Nair","userId":"07528364206433752056"},"user_tz":-630},"id":"-vcSOQWSCawf","outputId":"d3d78802-85b1-4d70-ee60-28dd02054bcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-fid\n","  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n","Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n","Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n","Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pytorch-fid\n","Successfully installed pytorch-fid-0.3.0\n"]}],"source":["!pip install pytorch-fid"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16961,"status":"ok","timestamp":1764024265217,"user":{"displayName":"Akhila R Nair","userId":"07528364206433752056"},"user_tz":-630},"id":"WAHoy9hxM7w6","outputId":"e011b88b-62e8-4e21-b2a6-6850adfad91b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.12/dist-packages/pytorch_fid/__main__.py\", line 3, in <module>\n","    pytorch_fid.fid_score.main()\n","  File \"/usr/local/lib/python3.12/dist-packages/pytorch_fid/fid_score.py\", line 313, in main\n","    fid_value = calculate_fid_given_paths(args.path,\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pytorch_fid/fid_score.py\", line 253, in calculate_fid_given_paths\n","    raise RuntimeError('Invalid path: %s' % p)\n","RuntimeError: Invalid path: fid_fake_images\n"]}],"source":["# In a Jupyter/Colab notebook cell, use !\n","!python -m pytorch_fid fid_fake_images cifar10_test_real"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tj1fSaCACXgg"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNj2TBjKz8LggwhoyYM4yA6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}